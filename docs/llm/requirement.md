---
layout: default
nav_order: 1
title: ç³»ç»Ÿè¦æ±‚
parent: å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰
---

# ç³»ç»Ÿè¦æ±‚

---
## å†…å­˜è¦æ±‚

ä¸åŒçš„æ¨¡å‹è§„æ ¼ï¼Œéœ€è¦çš„ç‰©ç†å†…å­˜å¤§å°ä¸ç›¸åŒï¼Œæ¨¡å‹è¶Šå¤§ï¼Œæ¨ç†é€Ÿåº¦è¶Šæ…¢ã€‚

{: .important}
> ç”±äºå½“å‰åªæ”¯æŒ CPU æ¨ç†ï¼Œå»ºè®®ä¸è¦ä½¿ç”¨é«˜äº 7B çš„æ¨¡å‹è§„æ ¼ï¼Œæ¨èä½¿ç”¨ **Q4_0** é‡åŒ–åçš„æ¨¡å‹ï¼Œ ä»¥è¾¾åˆ°æœ€ä½³æ¨ç†é€Ÿåº¦ã€‚

**å†…å­˜è¦æ±‚**   

| Model | Original size |         Q4 size        |
|------:|--------------:|-----------------------:|
|    7B |         13 GB |                 3.9 GB |
|   13B |         24 GB |                 7.8 GB |
|   30B |         60 GB |                19.5 GB |
|   65B |        120 GB |                38.5 GB |

{: .highlight}
> æ¨ç†å¼•æ“ä¼šå°†æ¨¡å‹å…¨éƒ¨åŠ è½½åˆ°å†…å­˜ï¼Œå› æ­¤å†…å­˜çš„è¦æ±‚å’Œæ¨¡å‹åœ¨ç£ç›˜ä¸Šçš„å¤§å°ç›¸å½“ï¼ˆç•¥å¤§ï¼Œé™¤äº†æ¨¡å‹ï¼Œè¿˜éœ€è¦ç¼“å­˜ä¸€äº›å†…å®¹ï¼‰ã€‚
>
> Q4 è¡¨ç¤º 4bit é‡åŒ–ï¼Œä½ å¯ä»¥é€šè¿‡ Q4 çš„å°ºå¯¸æ¨æ–­å‡ºå…¶ä»–é‡åŒ–æ ¼å¼çš„æ¨¡å‹å¤§å°ã€‚

---   

## æ¨¡å‹æ”¯æŒ   

ç›®å‰ MediaPipe4ULLM ä½¿ç”¨ [llama.cpp](https://github.com/ggerganov/llama.cpp)ä½œä¸ºæ¨ç†åç«¯ï¼Œå› æ­¤æ”¯æŒçš„æ¨¡å‹å’Œ llama.cpp ä¿æŒä¸€è‡´ï¼š

- [X] LLaMA ğŸ¦™
- [x] LLaMA 2 ğŸ¦™ğŸ¦™
- [X] [Alpaca](https://github.com/ggerganov/llama.cpp#instruction-mode-with-alpaca)
- [X] [GPT4All](https://github.com/ggerganov/llama.cpp#using-gpt4all)
- [X] [Chinese LLaMA / Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) and [Chinese LLaMA-2 / Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)
- [X] [Vigogne (French)](https://github.com/bofenghuang/vigogne)
- [X] [Vicuna](https://github.com/ggerganov/llama.cpp/discussions/643#discussioncomment-5533894)
- [X] [Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/)
- [X] [OpenBuddy ğŸ¶ (Multilingual)](https://github.com/OpenBuddy/OpenBuddy)
- [X] [Pygmalion 7B / Metharme 7B](#using-pygmalion-7b--metharme-7b)
- [X] [WizardLM](https://github.com/nlpxucan/WizardLM)
- [X] [Baichuan-7B](https://huggingface.co/baichuan-inc/baichuan-7B) and its derivations (such as [baichuan-7b-sft](https://huggingface.co/hiyouga/baichuan-7b-sft))
- [X] [Aquila-7B](https://huggingface.co/BAAI/Aquila-7B) / [AquilaChat-7B](https://huggingface.co/BAAI/AquilaChat-7B)

---   

## æ€§èƒ½å‚è€ƒ

ä¸åŒçš„ CPU å¯èƒ½å¯¹æ€§èƒ½äº§ç”Ÿä¸€å®šå½±å“ï¼Œä¸€ä¸‹ä¸ºæˆ‘çš„å¼€å‘ç¯å¢ƒå®æµ‹çš„æ•°æ®ï¼š

CPU: AMD3600   
RAM: 32G   
GPU: NVIDIA GTX 2060 (6G)   

é€Ÿåº¦ï¼š **5.5**-**6.5** TPS (tokens per second)



